# Mind Gateway
Curated resources on Artifical Intelligence (AI), Machine Learning (ML), Philosophy of Mind (PoM), and related topics.

## Contents
1. [Artificial Intelligence](#artificial-intelligence)
   + ðŸ“– [On Intelligence](#on-intelligence) `layperson`
   + ðŸ’¯ ðŸ“º [MIT Artificial Intelligence](#mit-artificial-intelligence) `beginner`
   + ðŸ“º [The AI Podcast](#the-ai-podcast) `layperson`
2. [General Machine Learning](#general-machine-learning)
   + ðŸ’¯ ðŸ“º ðŸ“– [Learning from Data](#learning-from-data) `intermediate`
   + ðŸ“– [Mathematics for Machine Learning](#mathematics-for-machine-learning) `intermediate`
   + ðŸ“– [An Introduction to Statistical Learning](#an-introduction-to-statistical-learning) `intermediate`
   + ðŸ’¯ ðŸ“º [Intuitive Machine Learning](#intuitive-machine-learning) `beginner`
   + ðŸ“° [Papers with Code](#papers-with-code)
   + ðŸ“° [Papers Daily](#papers-daily)
3. [Deep Learning](#deep-learning)
   + ðŸ’¯ ðŸ“º ðŸ“– [Deep Learning for Coders](#deep-learning-for-coders) `beginner`
   + ðŸ§” ðŸ“º [Heroes of Deep learning](#heroes-of-deep-learning) `intermediate`
4. [Philosophy of Mind](#philosophy-of-mind)
   + ðŸ’¯ ðŸ“– [GÃ¶del, Escher, Bach -- an Eternal Golden Braid](#gÃ¶del-escher-bach----an-eternal-golden-braid) `layperson`
   + ðŸ“– [The Society of Mind](#the-society-of-mind) `layperson`
   + ðŸ“– [I Am a Strange Loop](#i-am-a-strange-loop) `layperson`

## Artificial Intelligence
#### [On Intelligence](https://en.wikipedia.org/wiki/On_Intelligence) 
ðŸ“– by [Jeff Hawkins](https://en.wikipedia.org/wiki/Jeff_Hawkins) (2005)

The book explains why previous attempts at understanding intelligence and building intelligent machines have failed. It then introduces and develops the core idea of a proposed theory for how the human neocortex generates intelligent behavior, which the author calls the memory-prediction framework.

#### [MIT Artificial Intelligence](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi)
ðŸ’¯ ðŸ“º by [Patrick Winston](https://en.wikipedia.org/wiki/Patrick_Winston) (2010)

A series of lectures on general AI concepts, including reasoning, problem solving, search in problem spaces, cognitive architectures, probabilistic inference, among others. Even though the topics covered can be found in other similar books and courses, what makes this course special is Patrick's clear exposition, and his particular focus on key ideas and insights in each topic.

#### [The AI Podcast](https://lexfridman.com/podcast/)
ðŸ“º by [Lex Fridman](https://lexfridman.com/) (2015)

This podcast started as a series of conversations with some renowned AI/ML researchers (each episode is typically 2 hours long), but over time has expanded to related (and sometimes not so related) topics and themes. Guests include well-known physicists, mathematicians, economists, neuroscientists, etc. The content is not very technical, but from time to time the conversations can be hard to follow unless one has some prerequisite knowledge.

## General Machine Learning
#### [Learning from Data](https://work.caltech.edu/telecourse) 
ðŸ’¯ ðŸ“º ðŸ“– by [Yaser Abu-Mostafa](https://en.wikipedia.org/wiki/Yaser_Abu-Mostafa) (2012)

An introduction to ML with a strong focus on providing a conceptual and theoretical framework for the subject. It's an excellent complement to other courses which provide practical tools for machine learning but fail to explain in sufficient detail the conceptual underpinnings.

#### [Mathematics for Machine Learning](https://mml-book.github.io/)
ðŸ“– by [Marc Peter Deisenroth](https://deisenroth.cc/), [A. Aldo Faisal](https://www.imperial.ac.uk/people/a.faisal), and [Cheng Soon Ong](http://www.ong-home.my/) (2020)

An introduction to the mathematical tools most commonly used in ML/AI. Though it's possible to understand a lot of things in ML/AI without deep knowledge in mathematics, I believe that a solid understanding of these mathematical tools can be very valuable for any practitioner, and indispensable for researchers looking to build their own models or improve the state of the art. 

#### [An Introduction to Statistical Learning](https://www.statlearning.com/)
ðŸ“– by [Gareth James](http://faculty.marshall.usc.edu/gareth-james/), [Daniela Witten](https://www.danielawitten.com/), [Travor Hastie](https://web.stanford.edu/~hastie/), and [Rob Tibshirani](http://statweb.stanford.edu/~tibs/) (2021)

The book provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in various fields of science. It presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more.

#### [Intuitive Machine Learning](https://www.youtube.com/c/IntuitiveMachineLearning)
ðŸ“º by [Intuitive Machine Learning](https://twitter.com/intuitiveml) (2020)

One of the best resources for concise introductions to various topics in ML I've found so far. In just a few minutes, it summarizes topics that other people take half an hour or more to explain. The key to doing this is that the author focuses on key ideas, uses animations to improve visual communication, and omits unnecessary detail for an introduction. Beware you won't necessarily understand a topic deeply after watching a video, but you will have a good conceptual framework so more thorough explanations make absolute sense.

#### [Papers with Code](https://paperswithcode.com/)
ðŸ“° by [Facebook AI Research](https://ai.facebook.com/) (2018)

Papers with Code was created with the simple idea of helping the community track newly published machine learning papers with source code and quickly understand the current state of the art. It organizes a lot of the papers published in the field, providing summaries and related resources. Although it's sponsored by Facebook AI Research, it is an open community project.

#### [Papers Daily](https://papers.labml.ai/papers/daily)
ðŸ“° by [labml.ai](https://labml.ai/) (2020)

Papers Daily tracks recent and trending research papers in machine learning, aggregating comments from social media platforms (including Twitter, Reddit, and HackerNews) where people are talking about each paper.

## Deep Learning
#### [Deep Learning for Coders](https://course.fast.ai/)
ðŸ’¯ ðŸ“º ðŸ“– by [FastAI](https://www.fast.ai/) (2020)

This is a course on Deep Learning that follows a non-traditional approach to the subject, deemed more suitable for coders or less mathematically-inclined people. It starts by giving you the tools to build models right away instead of making you go through a lot of theory and concepts before you can see a model in action. Once you've gained a high-level appreciation of Deep Learning, it then gradually unveils more and more details of the underlying machinery building up to a full nuts-and-bolts understanding of the subject.

#### [Heroes of Deep Learning](https://youtube.com/playlist?list=PLkDaE6sCZn6FcbHlDzbVzf3TVgxzxK7lr)
ðŸ§” ðŸ“º by [Deep Learning AI](https://www.deeplearning.ai/) (2017)

A series of relatively short interviews by [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng) with various leading researchers in the field of machine learning. This is not really a technical resource, but I think it's interesting to hear the stories on how they got started, what ideas they've pursued and are currently pursuing, as well as their thoughts on current AI/ML trends and research.

## Philosophy of Mind
#### [GÃ¶del, Escher, Bach -- an Eternal Golden Braid](https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach) 
ðŸ’¯ ðŸ“– by [Douglas Hofstadter](https://en.wikipedia.org/wiki/Douglas_Hofstadter) (1979)

The book discusses how systems can acquire meaningful context despite being made of "meaningless" elements. It also discusses self-reference and formal rules, isomorphism, what it means to communicate, how knowledge can be represented and stored, the methods and limitations of symbolic representation, and even the fundamental notion of "meaning" itself.

#### [The Society of Mind](https://en.wikipedia.org/wiki/Society_of_Mind)
ðŸ“– by [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky) (1986)

The book presents a theory of how the mind may work, focusing on the conceptual level and without making reference to the underlying substrate (i.e., neurons). The author develops theories about how processes such as language, memory, and learning work, and also covers concepts such as consciousness, the sense of self, and free will.

#### [I Am a Strange Loop](https://en.wikipedia.org/wiki/I_Am_a_Strange_Loop)
ðŸ“– by [Douglas Hofstadter](https://en.wikipedia.org/wiki/Douglas_Hofstadter) (2007)

Although "GÃ¶del, Escher, Bach" (a.k.a. GEB) enjoyed great success--having even won a Pulitzer price--and inspired many future researchers on AI, ML, complex systems, etc., the author lamented in later years that many people seemed to have missed what he considered the central theme in his book. Hofstadter sought to remedy that in this new book by focusing on and expounding on that central theme, which he summarized as _"GEB is a very personal attempt to say how it is that animate beings can come out of inanimate matter. What is a self, and how can a self come out of stuff that is as selfless as a stone or a puddle?"_.

Another change...
